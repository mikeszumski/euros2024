{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76fd3bf2-3efc-415d-8e09-4e09767495b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec529d29-1dfb-4234-a84e-5421b0437267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line breaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a35178-13f6-47af-a276-943aeaa06ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MatchesCombined_v3winners_training_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m match_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatchesCombined_v3winners_training_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m match_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MatchesCombined_v3winners_training_data.csv'"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "match_data = pd.read_csv(\"MatchesCombined_v3winners_training_data.csv\")\n",
    "match_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce97c9e-9a72-40b1-aac5-5d8726a7fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine \"home_team_code\" and \"away_team_code\" into one new column \"team_code\"\n",
    "\n",
    "# Create a dataframe for home teams\n",
    "\n",
    "home_match_data = match_data.copy()\n",
    "\n",
    "home_match_data['team_code'] = home_match_data['home_team_code']\n",
    "\n",
    "home_match_data['opponent_code'] = home_match_data['away_team_code']\n",
    "\n",
    "home_match_data['home_or_away'] = 'home'\n",
    "\n",
    "home_match_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada49e1-8384-475d-8adb-1720f7ca63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for away teams\n",
    "\n",
    "away_match_data = match_data.copy()\n",
    "away_match_data['team_code'] = away_match_data['away_team_code']\n",
    "away_match_data['opponent_code'] = away_match_data['home_team_code']\n",
    "away_match_data['home_or_away'] = 'away'\n",
    "\n",
    "away_match_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905921ce-595b-4003-8035-0540bf151a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two dataframes\n",
    "combined_match_data = pd.concat([home_match_data, away_match_data], ignore_index=True)\n",
    "\n",
    "combined_match_data.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e2faf-ca0a-4f9a-900a-df2d9690e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by 'team_code' alphabetically\n",
    "combined_match_data = combined_match_data.sort_values(by='team_code')\n",
    "\n",
    "# Reset the index after sorting\n",
    "combined_match_data = combined_match_data.reset_index(drop=True)\n",
    "\n",
    "# Display the tail of the new dataframe\n",
    "combined_match_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85ef05-c238-4732-aacb-d48c7ccd5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_match_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e3553-fcab-4886-87f3-e87468f97794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "\n",
    "new_combined_match_data = combined_match_data.drop(columns=['winner', \n",
    "                                                        'winner score', \n",
    "                                                        'home_team_code', \n",
    "                                                        'away_team_code', \n",
    "                                                        'home_team', \n",
    "                                                        'away_team',\n",
    "                                                        'home_penalty',\n",
    "                                                        'away_penalty',\n",
    "                                                        'stadium_name',\n",
    "                                                        'stadium_name_media',\n",
    "                                                        'stadium_name_official',\n",
    "                                                        'stadium_name_event',\n",
    "                                                        'stadium_name_sponsor',\n",
    "                                                        'red_cards',\n",
    "                                                        'game_referees',\n",
    "                                                        'stadium_city',\n",
    "                                                        'goals',\n",
    "                                                        'date_time',\n",
    "                                                        'utc_offset_hours',\n",
    "                                                        'group_name',\n",
    "                                                        'matchday_name',\n",
    "                                                        'condition_humidity', \n",
    "                                                        'condition_pitch',\n",
    "                                                        'condition_temperature',\n",
    "                                                        'condition_weather', \n",
    "                                                        'condition_wind_speed', \n",
    "                                                        'status', \n",
    "                                                        'type', \n",
    "                                                        'round',\n",
    "                                                        'round_mode',\n",
    "                                                        'stadium_id', \n",
    "                                                        'stadium_country_code',\n",
    "                                                        'stadium_capacity',\n",
    "                                                        'stadium_name_media',\n",
    "                                                        'stadium_name_official', \n",
    "                                                        'stadium_name_event', \n",
    "                                                        'stadium_name_sponsor','winner.1',\n",
    "                                                        'winner_reason', \n",
    "                                                        'year',\n",
    "                                                        'penalties_missed',\n",
    "                                                        'penalties',\n",
    "                                                        'home_score_total',\n",
    "                                                        'away_score_total'])\n",
    "\n",
    "new_combined_match_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d034c-70c8-418d-a321-be9a63314277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_column(df, column_name, new_position):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.insert(new_position, cols.pop(cols.index(column_name)))\n",
    "    return df[cols]\n",
    "\n",
    "# Move column 'D' to be the second column\n",
    "adjusted_match_data_df = move_column(new_combined_match_data, 'team_code', 1)\n",
    "\n",
    "adjusted_match_data_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fb338-9778-4144-b3e1-a54d20808919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the first 4 rows\n",
    "\n",
    "adjusted_match_data_drop_rows_df = adjusted_match_data_df.drop(index=adjusted_match_data_df.index[:4])\n",
    "\n",
    "adjusted_match_data_drop_rows_df = adjusted_match_data_drop_rows_df.reset_index(drop=True)\n",
    "\n",
    "adjusted_match_data_drop_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4ad57-5ab8-4e18-be23-7cea8ccca08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the column names if necessary\n",
    "new_team_data = adjusted_match_data_drop_rows_df.rename(columns={\n",
    "    \"home XG\": \"team_xG\",\n",
    "    \"home odds to win\": \"team_odds\",\n",
    "    \"away XG\": \"opponent_xG\",\n",
    "    \"away odds to win\": \"opponent_odds\",\n",
    "    \"home_score\": \"team_score\",\n",
    "    \"away_score\": \"opponent_score\",\n",
    "    \"home_penalty\": \"team_penalty\",\n",
    "    \"away_penalty\": \"opponent_penalty\",\n",
    "    \"Target - 1 means home team will be in the top 4\": \"target_top_4\"\n",
    "})\n",
    "\n",
    "new_team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e35ff-528f-460b-bb5d-731d467ae080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the last 8 rows\n",
    "new_team_data_row_delete = new_team_data.drop(index=new_team_data.index[-8:])\n",
    "\n",
    "# Reset the index after deleting rows\n",
    "new_team_data_row_delete = new_team_data_row_delete.reset_index(drop=True)\n",
    "\n",
    "# Display the modified dataframe\n",
    "new_team_data_row_delete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39026b-090c-4861-9473-f40f599e3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any leading/trailing spaces and convert to lowercase\n",
    "new_team_data_row_delete['home_or_away'] = new_team_data_row_delete['home_or_away'].str.strip().str.lower()\n",
    "\n",
    "# Change home_or_away value from string to int \n",
    "\n",
    "new_team_data_row_delete['home_or_away'] = new_team_data_row_delete['home_or_away'].map({'home': 1, 'away': 0})\n",
    "\n",
    "new_team_data_row_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea2aff-d19f-4b10-a75b-ff84251bdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'id_match', 'opponent_odds', 'team_score', 'opponent_score', 'match_attendance', and 'target_top_4' columns from float to int\n",
    "\n",
    "# Columns to convert\n",
    "columns_to_convert = ['id_match', 'opponent_odds', 'team_score', 'opponent_score', 'match_attendance', 'target_top_4']\n",
    "\n",
    "# Handle NaN values if any (e.g., fill with 0)\n",
    "new_team_data_row_delete[columns_to_convert] = new_team_data_row_delete[columns_to_convert].fillna(0)\n",
    "\n",
    "# Convert the specified columns from float to int\n",
    "new_team_data_row_delete[columns_to_convert] = new_team_data_row_delete[columns_to_convert].astype(int)\n",
    "\n",
    "new_team_data_row_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4c649-744b-4ded-9c04-1d5e45db77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new order of columns\n",
    "\n",
    "euro_team_data = ['id_match', \n",
    "                  'date', \n",
    "                  'source', \n",
    "                  'home_or_away', \n",
    "                  'team_code', \n",
    "                  'team_xG', \n",
    "                  'team_odds', \n",
    "                  'opponent_code', \n",
    "                  'opponent_xG', \n",
    "                  'opponent_odds', \n",
    "                  'team_score', \n",
    "                  'opponent_score', \n",
    "                  'match_attendance', \n",
    "                  'stadium_latitude', \n",
    "                  'stadium_longitude', \n",
    "                  'stadium_pitch_length', \n",
    "                  'stadium_pitch_width', \n",
    "                  'target_top_4']\n",
    "\n",
    "# Create a new dataframe with columns in the new order\n",
    "euro_team_data_df = new_team_data_row_delete[euro_team_data]\n",
    "\n",
    "euro_team_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bef74-6db3-402b-a5c2-42dd89f1705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 0s in the match_attendance column\n",
    "count_zeros = euro_team_data_df['match_attendance'].value_counts().get(0, 0)\n",
    "\n",
    "count_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c0668-c880-4c9e-8175-3113269f2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of match_attendance excluding 0 values\n",
    "mean_attendance = euro_team_data_df.loc[euro_team_data_df['match_attendance'] != 0, 'match_attendance'].mean()\n",
    "\n",
    "# Replace 0 values with the mean attendance using .loc\n",
    "euro_team_data_df.loc[:, 'match_attendance'] = euro_team_data_df['match_attendance'].replace(0, mean_attendance)\n",
    "\n",
    "# Convert match_attendance from float to int using .loc\n",
    "euro_team_data_df['match_attendance'] = euro_team_data_df['match_attendance'].astype(int)\n",
    "\n",
    "euro_team_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf14bf1-15f8-4aa5-ab67-e5cf0e0cfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where the team is listed as \"home_or_away\", and where they are listed as away switch the \"team_xG\" and \"opponent_xG\"\n",
    "\n",
    "# Find rows where home_or_away is 0\n",
    "away_matches = df[df['home_or_away'] == 0]\n",
    "\n",
    "# Switch team_xG and opponent_xG for away matches\n",
    "df.loc[away_matches.index, ['team_xG', 'opponent_xG']] = df.loc[away_matches.index, ['opponent_xG', 'team_xG']].values\n",
    "\n",
    "# Switch team_odds and opponent_odds for away matches\n",
    "df.loc[away_matches.index, ['team_odds', 'opponent_odds']] = df.loc[away_matches.index, ['opponent_odds', 'team_odds']].values\n",
    "\n",
    "# Switch team_score and opponent_score for away matches\n",
    "df.loc[away_matches.index, ['team_score', 'opponent_score']] = df.loc[away_matches.index, ['opponent_score', 'team_score']].values\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Corrected Euro Team Data\", dataframe=df)\n",
    "\n",
    "# Display the corrected dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f38319-100c-4f99-aebe-e7584cdf1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get dummies on 'team_code', 'opponent_code', 'source'\n",
    "\n",
    "# # Identify the categorical columns\n",
    "# categorical_columns = ['source', 'team_code', 'opponent_code']\n",
    "\n",
    "# # Use get_dummies to one-hot encode these columns\n",
    "# team_data_df_encoded = pd.get_dummies(new_team_data_row_delete, columns=categorical_columns)\n",
    "\n",
    "# team_data_df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0eeb2d-0b00-430b-b3d2-e6dac45eed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# euro_team_data_df.to_csv('euro_team_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9b864-e158-49fa-8e4f-71795a957802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#standard scaling on the final data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
